# 분류자
## Data

|예제|폭|길이|곤충|
|------|---|---|---|
|1|3.0|1.0|무당벌레|
|2|1.0|3.0|애벌레|

<br/>

이처럼 예측자 or 분류자에게 실제 값을 알려주는 예제 데이터를 학습 데이터(Training Data)라고 부름.
전 예제와 같이 선형관계<br/>

![file](https://user-images.githubusercontent.com/81912557/137285215-6d979549-9f2d-4e86-a553-dc40bf93f6a8.jpg)<br/>

- 2개의 그룹<br/>
- 직선의 활용 용도? -> 미지의 곤충들을 측정 값(폭과 길이)에 기초해 분류하는 용도<br/>
- ※ 현재의 경우에는 역할을 제대로 하지 못함 -> 매개변수인 기울기를 조정<br/>

![file2](https://user-images.githubusercontent.com/81912557/137285765-152befee-2f98-4947-9139-f1908e39a3bd.jpg)

이 직선은 곤충의 분류자(Classifier)로 이용할 수 있음.<br>
미지의 곤충이라도 직선의 위에 위치하면 애벌레, 밑에 위치하면 무당벌레로 분류가 가능함.<br>

### ❓ 과연 이 기울기는 어떻게 구하는 것일까?

# 분류자 학습 시키기
- 우리는 선형 분류자를 학습시켜서 애벌레와 무당벌레를 잘 분류할 수 있게 만들고자 한다.
- 다음과 같은 Data가 주어졌다고 가정.<br>

|예제|폭|길이|곤충|
|------|---|---|---|
|1|3.0|1.0|무당벌레|
|2|1.0|3.0|애벌레|

- 현재 (3.0,1.0)은 무당벌레이고 (1.0,3.0)은 애벌레 인 Data / (폭,길이)
실제 값인 Data -> Training Data를 이용해 기울기를 구할것임.

가정<br>
원점을 지나는 직선 -> 직선은 y=Ax <br>

     A=매개변수
     A가 커질수록 직선의 기울기도 커짐

### If A=0.25<br>
![file](https://user-images.githubusercontent.com/81912557/137288974-4e5a810d-8295-4c9a-945a-394630ce22bc.jpg)<br>
- 2가지 곤충을 전혀 분류하지 못함.<br>
- 직관적으로 기울기가 커야한다는 것을 알고 직접 그리는게 빠르겠지만 실제는 수많은 Data가 있으므로 불가능함.<br>
  기울기를 조금씩 올려주는 컴퓨터 명령으로 A를 찾아야함.<br>
  특정 목적을 가진 일련의 컴퓨터 명령 -> Algorithm<br>
  
  y=Ax 1번 학습데이터 무당벌레 대입.<br>
  
       y=0.25*3.0, y=0.75, 실제 y값은 1.0
       error발생
       또한 y값이 1.0이 될 경우 무당벌레인 점을 통과하게 되므로 y=1.0보다 위쪽에 위치해야함.
       
 -> Target y=1.1<br>
error=1.1-0.75 / error=0.35<br>
- 시각화<br>

![file](https://user-images.githubusercontent.com/81912557/137302915-03b25b8b-5368-4008-8219-f43553c896aa.jpg)
     
### ❓ 어떻게 하면 A값을 정교화 할 수 있는가?
- E와 A의 관계 파악
 
      1. y=Ax
      (※ A 초기 값을 임의로 설정한다면 잘못된 y값을 얻게 됨)
      2. 목표값을 t로 설정
      t=(A+ΔA)x / 여기서 Δ는 작은 변화량
      3. 계산
      t=(A+ΔA)x
      y=Ax
      타겟-출력값=Error
      Error=t-y
      Error=ΔAx
      기울기 A개선을 위해 ΔA로 정리하면
      ΔA=Error/x, 즉 ΔA만큼 A를 증가시켜 나가면 Error의 기초해 조정이 가능하다.
      
 -> Update
 - E=0.35, x=3.0
      
       ΔA=0.35/3 / ΔA=Error/x
       A를 0.1167만큼 update
       
 - y=0.3667x , x=3.0
 
       0.3667*3.0=1.1

target 달성<br>
  y=0.3667x 2번 학습데이터 애벌레 대입.<br>
  x=1.0, y=3.0
  
    y=0.3667*1.0 -> y=0.3667 
    Error발생
    Y=3.0보다 아래에 위치 해야함.
    target y=2.9
    Error=t-y / Error=2.9-0.3667 -> 2.5333

-> Update
- E=2.5333, x=1.0

      ΔA=2.5533/1.0 -> 2.5333
      A를 2.5333만큼 update

- y=2.9x, x=1.0<br>

target달성<br>

- 시각화<br>
![file](https://user-images.githubusercontent.com/81912557/137308214-c7c8f861-fb74-4f11-9265-d8b692c9e08f.jpg)<br>

아직까지도 직선의 기울기는 더욱 개선되어야 함.<br>
WHY? -> y에 대해 target을 기준으로 개선되었기 때문이다.<br>
### ❓ 어떻게 하면 해결할 수 있을까?
- 각 A값으로 바로 넘어가는 것이 아니라, 조금씩 조정하여 ΔA의 일부만 업데이트 하는것.
  즉 여러 번의 학습에 기초해 업데이트 된 값을 유지하면서, 학습 데이터가 제시하는 방향으로 조금씩만 움직이는 것.
 
      ΔA=L(E/x)
      머신러닝에서는 L을 Learning Rate 학습률이라 부른다.
      Ex. L=0.5
      1차 업데이트에서 ΔA값은 0.0583으로 개선방향은 유지한채 변동폭을 줄일 수 있다.
      
      
      
   ### 핵심정리
   - 간단한 계산을 통헤서 선형 분류자의 오차와 기울기 매개변수 간의 관계를 이해할 수 있다.<br>
     즉, 오차 제거를 위한 기울기의 조정정도를 알 수 있다.
   - 조정과정의 문제점은 직전 학습 데이터에만 맞춰서 업데이트 된다는 점이다. 이를 해결하기 위해 학습룰(L)을 도입하여 개선방향은 유지한 채 변동폭을 줄여 
     직전 학습 데이터의 영향을 줄일 수 있다.
   - 현실의 학습 데이터는 잡음이 섞여있거나 오차를 가진다. 학습률(L)은 이러한 데이터 오류의 영향을 제한할 수 있다.
